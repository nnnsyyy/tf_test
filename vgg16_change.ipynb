{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize image and add bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "_img = 'images/xbox.jpg'\n",
    "image = Image.open(_img)\n",
    "image.thumbnail((224, 224), Image.ANTIALIAS)\n",
    "background = Image.new('RGB', (224, 224), (255, 255, 255))\n",
    "background.paste(\n",
    "    image, (int((224 - image.size[0]) / 2), int((224 - image.size[1]) / 2))\n",
    ")\n",
    "background.save(\"images/xbox_re\", \"JPEG\")\n",
    "imgplot = plt.imshow(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(background, interpolation=\"bicubic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image augmentation using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/shiyue/Desktop/workplace/vgg16_v1/images/'\n",
    "dir_list = glob.glob(PATH+'*')\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save\n",
      "save\n",
      "save\n",
      "save\n",
      "save\n",
      "save\n",
      "save\n",
      "save\n",
      "save\n",
      "save\n",
      "save\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array, load_img\n",
    "import glob\n",
    "\n",
    "PATH = '/home/shiyue/Desktop/workplace/vgg16_v1/images/'\n",
    "dir_list = glob.glob(PATH+'*')\n",
    "# SAVE_PATH = '/home/shiyue/Desktop/workplace/vgg16_v1/images/IA/'\n",
    "# name_list = glob.glob(PATH+'*/*')\n",
    "# 设置生成器参数\n",
    "datagen = image.ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            rotation_range=90 ,\n",
    "                            fill_mode='nearest',\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2)\n",
    "\n",
    "for dir_name in dir_list:\n",
    "    brand_list = glob.glob(dir_name+'/*')\n",
    "    for brand_name in brand_list:\n",
    "        device_list = glob.glob(brand_name+'/*')\n",
    "        for device_name in device_list:\n",
    "            img_list = glob.glob(device_name+'/*')\n",
    "            for img_name in img_list:\n",
    "            # TODO, import num_array as img\n",
    "                img = load_img(img_name)\n",
    "                img = img_to_array(img)\n",
    "                img = img.reshape((1,)+ img.shape)\n",
    "                gen_data = datagen.flow(x=img,\n",
    "                                        batch_size = 1,\n",
    "                                        shuffle = True,\n",
    "                                        save_to_dir = device_name,\n",
    "                                        save_format = 'jpeg'\n",
    "                                        )\n",
    "                count = 0\n",
    "                for batch in gen_data:\n",
    "                    count+=1\n",
    "                    if(count>5):\n",
    "                        print('save')\n",
    "                        break;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.applications.VGG16()\n",
    "imgfile = 'images/ps3.jpg'\n",
    "image = tf.keras.preprocessing.image.load_img(\n",
    "    imgfile, target_size=(224, 224))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "array = np.expand_dims(array, axis=0)\n",
    "# preprocess_input should be used \n",
    "array = tf.keras.applications.vgg16.preprocess_input(array)\n",
    "probabilities = model.predict(array)\n",
    "tf.keras.applications.vgg16.decode_predictions(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & restore model\n",
    "## Freeze the model and change the final layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyue/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 4096)              134260544 \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 134,301,514\n",
      "Trainable params: 40,970\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "model = VGG16(\n",
    "    include_top=True,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "vgg_model = Model(inputs=model.input, outputs=model.get_layer('fc2').output)\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Create your own input format (here 3x224x224)\n",
    "class_num = 10\n",
    "vgginput = Input(shape=(224,224,3),name = 'image_input')\n",
    "#Use the generated model \n",
    "output_vgg16_conv = vgg_model(vgginput)\n",
    "#Add the fully-connected layers \n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(class_num, activation='softmax', name='predictions')(x)\n",
    "#Create your own model \n",
    "my_model = Model(inputs=vgginput, outputs=x)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 10\n",
    "for layer in model.layers:\n",
    "#     print(layer.get_config())\n",
    "    if(layer.name!='predictions'):\n",
    "#         print(layer.name)\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        config = layer.get_config()\n",
    "        config['units'] = 10\n",
    "        layer. = Dense.from_config(config)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the conv level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "model = VGG16(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None\n",
    "#     ,classes=1000\n",
    ")\n",
    "model.summary()\n",
    "for layer in model_vgg16_conv.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras/issues/4465\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.python.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "class_num = 10\n",
    "model_vgg16_conv = VGG16(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\n",
    "model_vgg16_conv.summary()\n",
    "\n",
    "#Create your own input format (here 3x224x224)\n",
    "vgginput = Input(shape=(224,224,3),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model_vgg16_conv(vgginput)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(class_num, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(inputs=vgginput, outputs=x)\n",
    "# my_model = Model(vgginput, x)\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()\n",
    "\n",
    "\n",
    "#Then training with your data ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple save and restore\n",
    "https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path \n",
    "\n",
    "result_path = './results'\n",
    "if not os.path.isdir(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = my_model.to_json()\n",
    "with open(os.path.join(result_path, \"vgg_self_model.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "my_model.save_weights(os.path.join(result_path, \"vgg16_self.h5\"))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open(os.path.join(result_path, 'vgg_self_model.json'), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(os.path.join(result_path, \"vgg16_self.h5\"))\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze conv and check with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras/issues/4465\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.python.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "class_num = 10\n",
    "model_vgg16_conv = VGG16(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\n",
    "for layer in model_vgg16_conv.layers:\n",
    "    layer.trainable = False\n",
    "model_vgg16_conv.summary()\n",
    "#Create your own input format (here 3x224x224)\n",
    "vgginput = Input(shape=(224,224,3),name = 'image_input')\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model_vgg16_conv(vgginput)\n",
    "\n",
    "with tf.variable_scope(\"New_FCs\"):\n",
    "    #Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(class_num, activation='softmax', name='predictions')(x)\n",
    "updatable_variables = tf.get_collection(\n",
    "                        tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                        scope='New_FCs')\n",
    "#Create your own model \n",
    "my_model = Model(inputs=vgginput, outputs=x)\n",
    "# my_model = Model(vgginput, x)\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
